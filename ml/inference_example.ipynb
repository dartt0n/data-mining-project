{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11772359,"sourceType":"datasetVersion","datasetId":7390948},{"sourceId":11772600,"sourceType":"datasetVersion","datasetId":7391126},{"sourceId":387112,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":319160,"modelId":339721}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.5.1+cu124.html --no-cache-dir\n!pip install pyg-lib -f https://data.pyg.org/whl/torch-2.5.1+cu124.html --no-cache-dir\n!pip install torch-geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:42:02.899494Z","iopub.execute_input":"2025-05-11T15:42:02.899772Z","iopub.status.idle":"2025-05-11T15:42:15.345057Z","shell.execute_reply.started":"2025-05-11T15:42:02.899749Z","shell.execute_reply":"2025-05-11T15:42:15.344275Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\nCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m199.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch-sparse\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_sparse-0.6.18%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (5.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m278.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.2)\nRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\nInstalling collected packages: torch-scatter, torch-sparse\nSuccessfully installed torch-scatter-2.1.2+pt25cu124 torch-sparse-0.6.18+pt25cu124\nLooking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\nCollecting pyg-lib\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/pyg_lib-0.4.0%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (2.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyg-lib\nSuccessfully installed pyg-lib-0.4.0+pt25cu124\nCollecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.16)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.19.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GINConv, SAGEConv\nfrom torch_geometric.data import Data\nfrom torch_geometric.transforms import RandomLinkSplit\nfrom torch_geometric.utils import coalesce, subgraph\nfrom tqdm.auto import tqdm # Still useful for data generation progress\nimport numpy as np\nimport random\nimport os # Import os for checking file existence\n\n# Function to set seeds for reproducibility (less critical for inference, but good practice)\ndef set_seed(seed: int = 42):\n    \"\"\"Sets the seed for reproducibility.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed) # for multi-GPU\n        # Optional: If you need deterministic behavior, uncomment these lines.\n        # This might slow down training.\n        # torch.backends.cudnn.deterministic = True\n        # torch.backends.cudnn.benchmark = False\n    print(f\"Random seed set to {seed}\")\n\n# Determine the device to use (single GPU or CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:42:22.969588Z","iopub.execute_input":"2025-05-11T15:42:22.969938Z","iopub.status.idle":"2025-05-11T15:42:28.046633Z","shell.execute_reply.started":"2025-05-11T15:42:22.969910Z","shell.execute_reply":"2025-05-11T15:42:28.045794Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nRandom seed set to 42\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class LinkPredictor(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, model_type='GIN'):\n        super(LinkPredictor, self).__init__()\n        self.num_layers = num_layers # Store the number of layers as an attribute\n        self.convs = torch.nn.ModuleList()\n        if model_type == 'GIN':\n            for i in range(num_layers):\n                # Using Linear layers within GINConv\n                nn_GIN = torch.nn.Sequential(\n                    torch.nn.Linear(in_channels if i == 0 else hidden_channels, hidden_channels),\n                    torch.nn.BatchNorm1d(hidden_channels),\n                    torch.nn.ReLU(),\n                    torch.nn.Linear(hidden_channels, hidden_channels),\n                    torch.nn.BatchNorm1d(hidden_channels),\n                    torch.nn.ReLU()\n                )\n                self.convs.append(GINConv(nn_GIN))\n        elif model_type == 'SAGE':\n            for i in range(num_layers):\n                # SAGEConv layers\n                self.convs.append(SAGEConv(in_channels if i == 0 else hidden_channels, hidden_channels))\n        else:\n            raise ValueError(\"Model type must be 'GIN' or 'SAGE'\")\n\n        # Linear layer for prediction (used in the predict method)\n        self.lin = torch.nn.Linear(2 * hidden_channels, out_channels)\n        self.model_type = model_type\n\n    def forward(self, x, edge_index):\n        # Pass node features through graph convolution layers\n        for conv_layer in self.convs:\n            # Ensure inputs to convolution are on the correct device\n            x = conv_layer(x, edge_index)\n            x = F.relu(x) # Apply ReLU activation after each layer\n        return x\n\n    # Predict method using dot product between node embeddings\n    # This method expects edge indices that are LOCAL to the provided embeddings `z`\n    def predict(self, z, edge_index_pos, edge_index_neg):\n        # Calculate scores for positive links\n        if edge_index_pos.numel() > 0:\n            row_pos, col_pos = edge_index_pos\n            pos_out = (z[row_pos] * z[col_pos]).sum(dim=-1)\n        else:\n            pos_out = torch.empty(0).to(z.device) # Handle case with no positive edges\n\n        # Calculate scores for negative links\n        if edge_index_neg.numel() > 0:\n            row_neg, col_neg = edge_index_neg\n            neg_out = (z[row_neg] * z[col_neg]).sum(dim=-1)\n        else:\n            neg_out = torch.empty(0).to(z.device) # Handle case with no negative edges\n\n        # Apply sigmoid to get probabilities\n        return torch.sigmoid(pos_out), torch.sigmoid(neg_out)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:46:00.912186Z","iopub.execute_input":"2025-05-11T15:46:00.912467Z","iopub.status.idle":"2025-05-11T15:46:00.921231Z","shell.execute_reply.started":"2025-05-11T15:46:00.912446Z","shell.execute_reply":"2025-05-11T15:46:00.920471Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import json\n\nwith open('/kaggle/input/team-prediction-inference-example/authors.json', 'r') as file:\n    author_index = json.load(file)\n\nauthor_embedings_np = np.load('/kaggle/input/team-prediction-inference-example/nodes.npy', mmap_mode='r')\nedges_np = np.load('/kaggle/input/edges-inference-1/edges (3).npy',allow_pickle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:14:09.533173Z","iopub.execute_input":"2025-05-11T17:14:09.533722Z","iopub.status.idle":"2025-05-11T17:14:09.606984Z","shell.execute_reply.started":"2025-05-11T17:14:09.533698Z","shell.execute_reply":"2025-05-11T17:14:09.606411Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"invert_author_index = {}\nfor key,value in author_index.items():\n    invert_author_index[value] = key","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:18:41.969432Z","iopub.execute_input":"2025-05-11T17:18:41.969699Z","iopub.status.idle":"2025-05-11T17:18:41.990152Z","shell.execute_reply.started":"2025-05-11T17:18:41.969680Z","shell.execute_reply":"2025-05-11T17:18:41.989540Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"edges_np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:14:19.086424Z","iopub.execute_input":"2025-05-11T17:14:19.086998Z","iopub.status.idle":"2025-05-11T17:14:19.091946Z","shell.execute_reply.started":"2025-05-11T17:14:19.086975Z","shell.execute_reply":"2025-05-11T17:14:19.091165Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"array([[     0,      0,      0, ...,  80695,  80695,  80695],\n       [     1,      2,      3, ..., 100669,  30314, 100670]], dtype=int32)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"x_features = torch.tensor(author_embedings_np, dtype=torch.float)\n# edges are typically (2, num_edges), representing source and target nodes\nedge_index = torch.tensor(edges_np, dtype=torch.long).contiguous() # Transpose to get (2, num_edges)\ndata_obj = Data(x=x_features, edge_index=edge_index, num_nodes=num_nodes)\nprint(\"Data object created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:14:56.025211Z","iopub.execute_input":"2025-05-11T17:14:56.025765Z","iopub.status.idle":"2025-05-11T17:14:58.340901Z","shell.execute_reply.started":"2025-05-11T17:14:56.025742Z","shell.execute_reply":"2025-05-11T17:14:58.340231Z"}},"outputs":[{"name":"stdout","text":"Data object created.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"full_graph_data = data_obj # This contains the entire graph structure\n\n# --- Model Initialization and Loading ---\n# Hyperparameters - must match the saved model's hyperparameters\n# Use the feature size from the generated data\nin_channels = 559\nhidden_channels = 32 # Keep consistent with training\nout_channels = 1 # Keep consistent with training\nnum_layers = 2 # Keep consistent with training\nmodel_type = 'GIN' # Must match the model type used for training\n\n# Initialize the model with the same architecture as the saved model\nmodel = LinkPredictor(in_channels, hidden_channels, out_channels, num_layers, model_type=model_type)\n\n# Define the path to your saved model checkpoint file\nmodel_checkpoint_path = '/kaggle/input/teams_prediction/pytorch/default/1/model_GIN_checkpoint_final.pth' \nmodel.load_state_dict(torch.load(model_checkpoint_path, map_location=device,weights_only=True))\nmodel.to(device)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:15:08.863542Z","iopub.execute_input":"2025-05-11T17:15:08.864073Z","iopub.status.idle":"2025-05-11T17:15:08.887147Z","shell.execute_reply.started":"2025-05-11T17:15:08.864048Z","shell.execute_reply":"2025-05-11T17:15:08.886563Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"LinkPredictor(\n  (convs): ModuleList(\n    (0): GINConv(nn=Sequential(\n      (0): Linear(in_features=559, out_features=32, bias=True)\n      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=32, out_features=32, bias=True)\n      (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    ))\n    (1): GINConv(nn=Sequential(\n      (0): Linear(in_features=32, out_features=32, bias=True)\n      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=32, out_features=32, bias=True)\n      (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n    ))\n  )\n  (lin): Linear(in_features=64, out_features=1, bias=True)\n)"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"target_node_index = 0\n\nwith torch.no_grad():\n    # Move full graph data to device for embedding computation\n    full_graph_data = full_graph_data.to(device)\n    all_node_embeddings = model(full_graph_data.x, full_graph_data.edge_index)\n\ntarget_node_embedding = all_node_embeddings[target_node_index]\n\ntarget_node_edges_mask = (full_graph_data.edge_index[0] == target_node_index) | (full_graph_data.edge_index[1] == target_node_index)\nexisting_neighbors = torch.unique(full_graph_data.edge_index[:, target_node_edges_mask].flatten())\n\nexisting_neighbors = existing_neighbors[existing_neighbors != target_node_index]\n\nexisting_neighbors_set = set(existing_neighbors.cpu().numpy())\n\npotential_target_nodes_indices = [\n    i for i in range(full_graph_data.num_nodes)\n    if i != target_node_index and i not in existing_neighbors_set\n]\n\npotential_target_nodes_indices = torch.tensor(potential_target_nodes_indices, dtype=torch.long).to(device)\n\npotential_edges_from_target = torch.stack([\n    torch.full_like(potential_target_nodes_indices, target_node_index),\n    potential_target_nodes_indices\n], dim=0).to(device)\n\nprint(f\"Evaluating potential links from node {target_node_index} to {potential_edges_from_target.size(1)} other nodes...\")\n\nwith torch.no_grad():\n     predicted_scores, _ = model.predict(all_node_embeddings, potential_edges_from_target, torch.empty(2, 0).to(device))\n\nranked_predictions = sorted(zip(potential_target_nodes_indices.cpu().numpy(), predicted_scores.cpu().numpy()),\n                            key=lambda x: x[1],\n                            reverse=True)\n\n# Display the top predicted links\ntop_k = 10 # Number of top links to display\nprint(f\"\\nTop {top_k} predicted links from Author {invert_author_index[target_node_index]} [node {target_node_index}] (excluding existing connections):\")\nfor node_idx, score in ranked_predictions[:top_k]:\n    print(f\"  -> Author {invert_author_index[node_idx]} [Node {node_idx}]: Score {score:.4f}\")\n\nprint(min(ranked_predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:20:20.683317Z","iopub.execute_input":"2025-05-11T17:20:20.683960Z","iopub.status.idle":"2025-05-11T17:20:20.763511Z","shell.execute_reply.started":"2025-05-11T17:20:20.683935Z","shell.execute_reply":"2025-05-11T17:20:20.762828Z"}},"outputs":[{"name":"stdout","text":"Evaluating potential links from node 0 to 100647 other nodes...\n\nTop 10 predicted links from Author /A5065430546 [node 0] (excluding existing connections):\n  -> Author /A5087615023 [Node 687]: Score 1.0000\n  -> Author /A5026302045 [Node 688]: Score 1.0000\n  -> Author /A5110213087 [Node 883]: Score 1.0000\n  -> Author /A5091324914 [Node 884]: Score 1.0000\n  -> Author /A5067637550 [Node 6370]: Score 1.0000\n  -> Author /A5022469337 [Node 7050]: Score 1.0000\n  -> Author /A5084108976 [Node 7052]: Score 1.0000\n  -> Author /A5108314166 [Node 7053]: Score 1.0000\n  -> Author /A5066149235 [Node 7054]: Score 1.0000\n  -> Author /A5005817118 [Node 7055]: Score 1.0000\n(10, 0.6423824)\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}