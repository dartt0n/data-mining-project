{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11764114,"sourceType":"datasetVersion","datasetId":7385403}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.5.1+cu124.html --no-cache-dir\n!pip install pyg-lib -f https://data.pyg.org/whl/torch-2.5.1+cu124.html --no-cache-dir\n!pip install torch-geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:53:34.036979Z","iopub.execute_input":"2025-05-11T11:53:34.037777Z","iopub.status.idle":"2025-05-11T11:53:43.225700Z","shell.execute_reply.started":"2025-05-11T11:53:34.037740Z","shell.execute_reply":"2025-05-11T11:53:43.224695Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\nRequirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt25cu124)\nRequirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt25cu124)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.2)\nRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch-sparse) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy->torch-sparse) (2024.2.0)\nLooking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\nRequirement already satisfied: pyg-lib in /usr/local/lib/python3.11/dist-packages (0.4.0+pt25cu124)\nRequirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.16)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.19.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\ntorch.__version__, torch.version.cuda","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:53:43.227372Z","iopub.execute_input":"2025-05-11T11:53:43.228303Z","iopub.status.idle":"2025-05-11T11:53:44.908794Z","shell.execute_reply.started":"2025-05-11T11:53:43.228271Z","shell.execute_reply":"2025-05-11T11:53:44.908202Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"('2.5.1+cu124', '12.4')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import torch_sparse","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:53:44.909544Z","iopub.execute_input":"2025-05-11T11:53:44.909937Z","iopub.status.idle":"2025-05-11T11:53:45.283126Z","shell.execute_reply.started":"2025-05-11T11:53:44.909892Z","shell.execute_reply":"2025-05-11T11:53:45.282558Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GINConv, SAGEConv\nfrom torch_geometric.data import Data\n# Import multiple metrics from sklearn\nfrom sklearn.metrics import roc_auc_score, f1_score, average_precision_score, ndcg_score\nfrom torch_geometric.transforms import RandomLinkSplit\nfrom torch_geometric.utils import negative_sampling, coalesce\nfrom torch_geometric.loader import LinkNeighborLoader\nfrom tqdm.auto import tqdm\nimport numpy as np\nimport random\n\ndef set_seed(seed: int = 42):\n    \"\"\"Sets the seed for reproducibility.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed) # for multi-GPU\n        # Optional: If you need deterministic behavior, uncomment these lines.\n        # This might slow down training.\n        # torch.backends.cudnn.deterministic = True\n        # torch.backends.cudnn.benchmark = False\n    print(f\"Random seed set to {seed}\")\n\nset_seed(42)\n\n# Determine the device to use (single GPU or CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:53:45.285401Z","iopub.execute_input":"2025-05-11T11:53:45.285917Z","iopub.status.idle":"2025-05-11T11:53:47.627748Z","shell.execute_reply.started":"2025-05-11T11:53:45.285897Z","shell.execute_reply":"2025-05-11T11:53:47.627060Z"}},"outputs":[{"name":"stdout","text":"Random seed set to 42\nUsing device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\nclass LinkPredictor(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, model_type='GIN'):\n        super(LinkPredictor, self).__init__()\n        self.num_layers = num_layers # Store the number of layers as an attribute\n        self.convs = torch.nn.ModuleList()\n        if model_type == 'GIN':\n            for i in range(num_layers):\n                # Using Linear layers within GINConv\n                nn_GIN = torch.nn.Sequential(\n                    torch.nn.Linear(in_channels if i == 0 else hidden_channels, hidden_channels),\n                    torch.nn.BatchNorm1d(hidden_channels),\n                    torch.nn.ReLU(),\n                    torch.nn.Linear(hidden_channels, hidden_channels),\n                    torch.nn.BatchNorm1d(hidden_channels),\n                    torch.nn.ReLU()\n                )\n                self.convs.append(GINConv(nn_GIN))\n        elif model_type == 'SAGE':\n            for i in range(num_layers):\n                # SAGEConv layers\n                self.convs.append(SAGEConv(in_channels if i == 0 else hidden_channels, hidden_channels))\n        else:\n            raise ValueError(\"Model type must be 'GIN' or 'SAGE'\")\n\n        # Linear layer for prediction (used in the predict method)\n        # Note: The original code defined this but didn't use it in predict.\n        # The predict method uses dot product. If you intended to use a linear layer\n        # for prediction, you would modify the predict method.\n        # Keeping it here as per original code structure, though it's unused in predict.\n        self.lin = torch.nn.Linear(2 * hidden_channels, out_channels)\n        self.model_type = model_type\n\n    def forward(self, x, edge_index):\n        # Pass node features through graph convolution layers\n        for conv_layer in self.convs:\n            # Ensure inputs to convolution are on the correct device (handled by loader batch.to(device))\n            x = conv_layer(x, edge_index)\n            x = F.relu(x) # Apply ReLU activation after each layer\n        return x\n\n    # Predict method using dot product between node embeddings\n    # This method now expects edge indices that are LOCAL to the provided embeddings `z`\n    def predict(self, z, edge_index_pos, edge_index_neg):\n        # Calculate scores for positive links\n        if edge_index_pos.numel() > 0:\n            # edge_index_pos should already be on the correct device and local to z\n            row_pos, col_pos = edge_index_pos\n            # Dot product between embeddings of connected nodes\n            pos_out = (z[row_pos] * z[col_pos]).sum(dim=-1)\n        else:\n            pos_out = torch.empty(0).to(z.device) # Handle case with no positive edges\n\n        # Calculate scores for negative links\n        if edge_index_neg.numel() > 0:\n            # edge_index_neg should already be on the correct device and local to z\n            row_neg, col_neg = edge_index_neg\n            # Dot product between embeddings of disconnected nodes\n            neg_out = (z[row_neg] * z[col_neg]).sum(dim=-1)\n        else:\n            neg_out = torch.empty(0).to(z.device) # Handle case with no negative edges\n\n        # Apply sigmoid to get probabilities\n        return torch.sigmoid(pos_out), torch.sigmoid(neg_out)\n\n# Helper function to create labels for positive and negative edges\ndef get_link_labels(pos_edge_index, neg_edge_index):\n    E_pos = pos_edge_index.size(1) # Number of positive edges\n    E_neg = neg_edge_index.size(1) # Number of negative edges\n    # Determine device based on input tensors\n    device = pos_edge_index.device if pos_edge_index.numel() > 0 else \\\n             (neg_edge_index.device if neg_edge_index.numel() > 0 else 'cpu')\n    # Create labels: 1 for positive, 0 for negative\n    labels = torch.cat([\n        torch.ones(E_pos, device=device),\n        torch.zeros(E_neg, device=device)\n    ], dim=0).float()\n    return labels\n\n# Training function adapted for LinkNeighborLoader\ndef train(model, loader, optimizer, device):\n    model.train() # Set model to training mode\n    total_loss = 0\n    total_edges = 0 # To track the number of edges processed for averaging loss\n\n    # Wrap the loader with tqdm for a progress bar\n    for batch in tqdm(loader, desc=\"Training\"):\n        optimizer.zero_grad() # Clear gradients for this batch\n\n        # Move batch data to the correct device\n        batch = batch.to(device)\n\n        # Compute node embeddings using the message-passing edges in the batch\n        # batch.x and batch.edge_index are already on the device\n        z = model(batch.x, batch.edge_index)\n\n        # LinkNeighborLoader provides the prediction edges directly in batch.edge_label_index\n        # and their labels in batch.edge_label.\n        # These indices should be LOCAL to the nodes in the batch's subgraph.\n\n        train_edge_label_index = batch.edge_label_index\n        train_edge_label = batch.edge_label\n\n        # Filter local edge_label_index to get positive and negative edges based on edge_label\n        pos_mask = train_edge_label == 1\n        neg_mask = train_edge_label == 0\n\n        pos_edge_index_local = train_edge_label_index[:, pos_mask]\n        neg_edge_index_local = train_edge_label_index[:, neg_mask]\n\n        # Handle cases where a batch might result in no positive or negative edges\n        if pos_edge_index_local.numel() == 0 and neg_edge_index_local.numel() == 0:\n            # print(\"Warning: No positive or negative training edges found in batch. Skipping batch.\")\n            continue # Skip this batch if no relevant edges\n\n        # Get predictions for positive and negative links using LOCAL indices\n        # The predict method now receives indices local to the batch's z tensor\n        pos_out, neg_out = model.predict(z, pos_edge_index_local, neg_edge_index_local)\n        # Get corresponding labels\n        labels = get_link_labels(pos_edge_index_local, neg_edge_index_local) # get_link_labels handles device\n\n        # Concatenate predictions for loss calculation\n        predictions = torch.cat([pos_out, neg_out], dim=0)\n\n        # Check if predictions or labels are empty before calculating loss\n        if predictions.numel() == 0 or labels.numel() == 0:\n            # print(\"Warning: No training predictions or labels in batch. Skipping batch.\")\n            continue # Skip this batch if no predictions or labels\n\n        # Calculate Binary Cross-Entropy loss\n        loss = F.binary_cross_entropy(predictions, labels)\n\n        loss.backward() # Backpropagate the loss\n        optimizer.step() # Update model parameters\n\n        total_loss += loss.item() * predictions.size(0) # Accumulate loss (scaled by number of predictions in batch)\n        total_edges += predictions.size(0) # Accumulate the number of edges processed\n\n    # Return average loss over all processed edges\n    if total_edges > 0:\n        return total_loss / total_edges\n    else:\n        return torch.tensor(0.0, device=device) # Return 0 if no edges were processed\n\n\n# Evaluation function for classification metrics (AUC, F1, MAP)\n@torch.no_grad() # Disable gradient calculation for evaluation\ndef evaluate_classification_metrics(model, loader, device):\n    model.eval() # Set model to evaluation mode\n    y_true = []\n    y_pred = []\n\n    # Wrap the loader with tqdm for a progress bar\n    for batch in tqdm(loader, desc=\"Evaluating Classification Metrics\"):\n        # Move batch data to the correct device\n        batch = batch.to(device)\n\n        # Compute node embeddings using the message-passing edges in the batch\n        z = model(batch.x, batch.edge_index)\n\n        # LinkNeighborLoader provides the prediction edges directly in batch.edge_label_index\n        # and their labels in batch.edge_label.\n        # These indices should be LOCAL to the nodes in the batch's subgraph.\n\n        eval_edge_label_index = batch.edge_label_index\n        eval_edge_label = batch.edge_label\n\n        # Filter local edge_label_index to get positive and negative edges based on edge_label\n        pos_mask = eval_edge_label == 1\n        neg_mask = eval_edge_label == 0\n\n        pos_edge_index_local = eval_edge_label_index[:, pos_mask]\n        neg_edge_index_local = eval_edge_label_index[:, neg_mask]\n\n        # Handle cases where a batch might result in no positive or negative edges\n        if pos_edge_index_local.numel() == 0 and neg_edge_index_local.numel() == 0:\n            continue # Skip this batch if no relevant edges\n\n        # Get predictions for positive and negative links using LOCAL indices\n        pos_out, neg_out = model.predict(z, pos_edge_index_local, neg_edge_index_local)\n        # Get corresponding labels (using the filtered labels)\n        labels = get_link_labels(pos_edge_index_local, neg_edge_index_local) # get_link_labels handles device\n\n        # Concatenate predictions for AUC calculation\n        predictions = torch.cat([pos_out, neg_out], dim=0)\n\n        # Check if predictions or labels are empty before processing\n        if predictions.numel() == 0 or labels.numel() == 0:\n            continue # Skip this batch\n\n        # Append to lists (move to CPU for scikit-learn)\n        y_pred.append(predictions.cpu())\n        y_true.append(labels.cpu())\n\n    # Concatenate all batch results\n    if len(y_true) == 0 or len(y_pred) == 0:\n         print(\"Warning: No evaluation batches processed for classification metrics. Metrics are not defined.\")\n         return {\n             'roc_auc': 0.0,\n             'f1': 0.0,\n             'map': 0.0, # MAP calculated on flat list\n         }\n\n    y_pred = torch.cat(y_pred, dim=0).numpy()\n    y_true = torch.cat(y_true, dim=0).numpy()\n\n    # --- Calculate Classification Metrics ---\n    metrics = {}\n\n    # ROC AUC\n    if len(set(y_true)) < 2:\n        print(f\"Warning: Only one class present in y_true ({set(y_true)}). ROC AUC, F1, and MAP are not defined.\")\n        metrics['roc_auc'] = 0.0\n        metrics['f1'] = 0.0\n        metrics['map'] = 0.0\n    else:\n        metrics['roc_auc'] = roc_auc_score(y_true, y_pred)\n\n        # F1 Score (requires a threshold, using 0.5)\n        y_pred_binary = (y_pred > 0.5).astype(int)\n        metrics['f1'] = f1_score(y_true, y_pred_binary)\n\n        # Mean Average Precision (MAP) - calculated on the flat list of predictions\n        metrics['map'] = average_precision_score(y_true, y_pred)\n\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:53:47.628704Z","iopub.execute_input":"2025-05-11T11:53:47.629273Z","iopub.status.idle":"2025-05-11T11:53:47.648964Z","shell.execute_reply.started":"2025-05-11T11:53:47.629241Z","shell.execute_reply":"2025-05-11T11:53:47.648222Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n# Evaluation function for ranking metrics (NDCG, MAP@k)\n@torch.no_grad()\ndef evaluate_ranking_metrics(model, data_split, device, num_neg_samples_per_pos=100):\n    model.eval()\n    # We need the full data object to sample negative edges and get node embeddings\n    # for ranking evaluation.\n    full_data = data_split # data_split contains the full graph structure for sampling\n\n    # Get positive edges from the evaluation split\n    eval_edge_label_index = data_split.edge_label_index\n    eval_edge_label = data_split.edge_label\n    pos_eval_edge_index_global = eval_edge_label_index[:, eval_edge_label == 1]\n\n    if pos_eval_edge_index_global.numel() == 0:\n        print(\"Warning: No positive edges found for ranking evaluation. NDCG and MAP are not defined.\")\n        return {'ndcg': 0.0, 'map_at_k': 0.0}\n\n    all_ndcg_scores = []\n    all_ap_scores = [] # Average Precision for MAP\n\n    # Create a LinkNeighborLoader specifically for the positive evaluation edges\n    # This will sample subgraphs for each positive edge and its sampled negatives,\n    # allowing us to compute embeddings in batches.\n    # We set batch_size to a larger value for efficiency.\n    ranking_batch_size = 2**10 # Increased batch size for ranking evaluation loader\n\n    ranking_loader = LinkNeighborLoader(\n        full_data, # Use the full data object for sampling\n        num_neighbors=[model.num_layers] * 2, # Sample enough neighbors for the model's receptive field\n        batch_size=ranking_batch_size, # Use a larger batch size\n        edge_label_index=pos_eval_edge_index_global, # Only provide the positive evaluation edges\n        edge_label=torch.ones(pos_eval_edge_index_global.size(1), dtype=torch.float), # Labels are all 1 for positive edges\n        neg_sampling_ratio=num_neg_samples_per_pos, # Sample negatives for each positive edge\n        shuffle=False, # Order doesn't matter for evaluation\n        num_workers=0, # Use 0 workers for simplicity in this specific ranking loop\n    )\n\n    # Iterate through batches from the ranking loader\n    for batch in tqdm(ranking_loader, desc=\"Evaluating Ranking Metrics\"):\n        # Move batch data to the correct device\n        batch = batch.to(device)\n\n        # Compute node embeddings for the nodes in this batch's subgraph\n        z = model(batch.x, batch.edge_index)\n\n        # The batch now contains multiple positive edges and their sampled negatives\n        ranking_edge_label_index_local = batch.edge_label_index\n        ranking_edge_label = batch.edge_label # Contains 1s for positive, 0s for negatives\n\n        # Ensure we have both positive and negative samples in this batch\n        if (batch.edge_label == 1).sum() == 0 or (batch.edge_label == 0).sum() == 0:\n             # print(\"Warning: Batch does not contain both positive and negative samples for ranking. Skipping.\")\n             continue\n\n        # Get prediction scores for the edges in this batch\n        # batch.edge_label_index contains the local indices of the prediction edges\n        pos_mask_in_batch = batch.edge_label == 1\n        neg_mask_in_batch = batch.edge_label == 0\n\n        pos_edge_index_local = ranking_edge_label_index_local[:, pos_mask_in_batch]\n        neg_edge_index_local = ranking_edge_label_index_local[:, neg_mask_in_batch]\n\n        pos_out, neg_out = model.predict(z, pos_edge_index_local, neg_edge_index_local)\n\n        # Combine positive and negative scores and labels for ranking\n        ranking_scores = torch.cat([pos_out, neg_out], dim=0).cpu().numpy()\n        # Use batch.edge_label directly for labels\n        ranking_labels = batch.edge_label.cpu().numpy()\n\n        # Calculate NDCG and Average Precision (for MAP) for this ranking\n        # NDCG@k requires specifying k. Let's use k = num_neg_samples_per_pos + 1 (positive + negatives)\n        k = num_neg_samples_per_pos + 1 # k is based on the number of sampled negatives per positive edge + the positive edge itself\n        # Ensure there are enough samples for NDCG@k calculation\n        if len(ranking_labels) >= k:\n             # Reshape for ndcg_score: y_true needs to be shape (n_samples, 1) or (n_samples,)\n             # y_score needs to be shape (n_samples,)\n             # Note: ndcg_score expects relevance scores (y_true) and prediction scores (y_score).\n             # Our labels are 1 for positive, 0 for negative, which are suitable as relevance scores.\n             all_ndcg_scores.append(ndcg_score(ranking_labels.reshape(1, -1), ranking_scores.reshape(1, -1), k=k))\n             # Average Precision (AP) for this positive edge\n             all_ap_scores.append(average_precision_score(ranking_labels, ranking_scores))\n        # else:\n             # print(f\"Warning: Not enough samples ({len(ranking_labels)}) for NDCG@{k}. Skipping.\")\n\n\n    # Calculate average NDCG and MAP over all processed positive edges\n    avg_ndcg = np.mean(all_ndcg_scores) if all_ndcg_scores else 0.0\n    avg_map = np.mean(all_ap_scores) if all_ap_scores else 0.0\n\n    return {'ndcg': avg_ndcg, 'map_at_k': avg_map}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:53:47.649751Z","iopub.execute_input":"2025-05-11T11:53:47.649990Z","iopub.status.idle":"2025-05-11T11:53:47.674965Z","shell.execute_reply.started":"2025-05-11T11:53:47.649967Z","shell.execute_reply":"2025-05-11T11:53:47.674216Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:53:47.675787Z","iopub.execute_input":"2025-05-11T11:53:47.676005Z","iopub.status.idle":"2025-05-11T11:53:47.691257Z","shell.execute_reply.started":"2025-05-11T11:53:47.675987Z","shell.execute_reply":"2025-05-11T11:53:47.690467Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# --- Example Usage with Larger Synthetic Data ---\n# Convert NumPy arrays to PyTorch tensors\n\nprint(\"Loading author embeddings and edges...\")\ntry:\n    # Use mmap_mode='r' for potentially large files to avoid loading everything into RAM at once\n    author_embedings_np = np.load('/kaggle/input/author_pred/pytorch/default/1/author_embeddings.npy', mmap_mode='r')\n    edges_np = np.load('/kaggle/input/edges-dm/edges.npy', mmap_mode='r')\n    print(\"Data loaded successfully.\")\n    print(f\"Author embeddings shape: {author_embedings_np.shape}\")\n    print(f\"Edges shape: {edges_np.shape}\")\nexcept FileNotFoundError:\n    print(\"Error: Make sure 'author_embeddings.npy' and 'edges.npy' are in the correct directory.\")\n\n\nx_features = torch.tensor(author_embedings_np, dtype=torch.float)\n# edges are typically (2, num_edges), representing source and target nodes\nedge_index = torch.tensor(edges_np, dtype=torch.long).contiguous() # Transpose to get (2, num_edges)\nprint(x_features.shape,edge_index.shape)\n\ndel author_embedings_np\ndel edges_np\n\n# Get the number of nodes. Assuming node IDs are 0-indexed up to the maximum ID in edges.\n# A safer approach is to use the shape of the feature matrix if it's guaranteed to have\n# features for all nodes 0 to num_nodes-1.\n# If node IDs in edges might not cover all nodes in the embedding matrix,\n# num_nodes should be derived from the embedding matrix shape.\nnum_nodes = x_features.size(0)\nprint(f\"Number of nodes inferred from embeddings: {num_nodes}\")\n\n# Make the graph undirected by adding reverse edges\n# Use coalesce to remove self-loops and duplicate edges after adding reverse edges\nedge_index = torch.cat([edge_index, edge_index.flip(0)], dim=-1)\nedge_index = coalesce(edge_index, num_nodes=num_nodes)\nprint(f\"Processed edge_index (undirected, no self-loops/duplicates) shape: {edge_index.shape}\")\n\n# Create the PyTorch Geometric Data object\n# Keep data on CPU initially\ndata_obj = Data(x=x_features, edge_index=edge_index, num_nodes=num_nodes)\nprint(\"PyTorch Geometric Data object created.\")\n\nprint(\"Data object created.\")\nprint(f\"Approximate RAM usage for data_obj: {(data_obj.x.element_size() * data_obj.x.numel() + data_obj.edge_index.element_size() * data_obj.edge_index.numel()) / (1024**3):.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:53:47.692206Z","iopub.execute_input":"2025-05-11T11:53:47.692489Z","iopub.status.idle":"2025-05-11T11:53:56.411900Z","shell.execute_reply.started":"2025-05-11T11:53:47.692465Z","shell.execute_reply":"2025-05-11T11:53:56.411183Z"}},"outputs":[{"name":"stdout","text":"Loading author embeddings and edges...\nData loaded successfully.\nAuthor embeddings shape: (3244445, 559)\nEdges shape: (2, 16784250)\ntorch.Size([3244445, 559]) torch.Size([2, 16784250])\nNumber of nodes inferred from embeddings: 3244445\nProcessed edge_index (undirected, no self-loops/duplicates) shape: torch.Size([2, 16111346])\nPyTorch Geometric Data object created.\nData object created.\nApproximate RAM usage for data_obj: 7.00 GB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Configure RandomLinkSplit\n# num_val=0.0 means no validation set\n# num_test=0.4 means 40% of edges will be used for testing (both positive and sampled negative)\n# is_undirected=True ensures edges are split symmetrically\n# add_negative_train_samples=True ensures negative samples are added to the training split's edge_label_index\nfrom torch_geometric.transforms import RandomLinkSplit\n\ntransform = RandomLinkSplit(\n    num_val=0.1,\n    num_test=0.1,\n    is_undirected=True,\n    add_negative_train_samples=True, # Ensure negative samples are generated for training\n)\n\n# Apply the transform to the data object\n# The resulting splits will be on CPU initially\nprint(\"Applying RandomLinkSplit transform...\")\ntrain_data_split, val_data_split, test_data_split = transform(data_obj)\nprint(\"Transform applied. Split data is on CPU.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:53:56.412561Z","iopub.execute_input":"2025-05-11T11:53:56.412806Z","iopub.status.idle":"2025-05-11T11:54:10.005836Z","shell.execute_reply.started":"2025-05-11T11:53:56.412777Z","shell.execute_reply":"2025-05-11T11:54:10.004921Z"}},"outputs":[{"name":"stdout","text":"Applying RandomLinkSplit transform...\nTransform applied. Split data is on CPU.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\n# --- Create LinkNeighborLoaders for mini-batching ---\n\n# Define the number of neighbors to sample for each layer\n# This is a critical parameter for memory usage and performance.\n# Adjust based on GPU memory. Higher values might increase GPU utilization\n# but require more memory.\nnum_neighbors = [10, 10] # Sample 10 neighbors for each of the 2 layers\n\n# Define the batch size for prediction edges.\n# Larger batch size can increase GPU utilization but requires more GPU memory.\n# Adjust based on GPU memory.\nbatch_size = 2**15\n\n# Define the number of CPU workers for data loading.\n# Increase this to speed up batch preparation and reduce GPU idle time,\n# provided you have enough CPU cores and RAM.\nnum_workers = 0 # Increased num_workers\n\n# Create the training LinkNeighborLoader\n# edge_label_index and edge_label specify the prediction edges for which\n# neighbors should be sampled (for both endpoints).\n# shuffle=True shuffles the order of batches of prediction edges.\ntrain_loader = LinkNeighborLoader(\n    train_data_split,\n    num_neighbors=num_neighbors,\n    batch_size=batch_size,\n    edge_label_index=train_data_split.edge_label_index, # Provide the edges for prediction\n    edge_label=train_data_split.edge_label, # Provide the labels for prediction edges\n    shuffle=True,\n    num_workers=num_workers,\n)\n\n# Create the test LinkNeighborLoader\n# For testing, use the test split's prediction edges.\n# shuffle=False as order doesn't matter for evaluation.\nval_loader = LinkNeighborLoader(\n    val_data_split,\n    num_neighbors=num_neighbors,\n    batch_size=batch_size,\n    edge_label_index=val_data_split.edge_label_index, # Provide the edges for prediction\n    edge_label=val_data_split.edge_label, # Provide the labels for prediction edges\n    shuffle=False,\n    num_workers=num_workers,\n)\n\ntest_loader = LinkNeighborLoader(\n    test_data_split,\n    num_neighbors=num_neighbors,\n    batch_size=batch_size,\n    edge_label_index=test_data_split.edge_label_index, # Provide the edges for prediction\n    edge_label=test_data_split.edge_label, # Provide the labels for prediction edges\n    shuffle=False,\n    num_workers=num_workers,\n)\n\nprint(f\"Created LinkNeighborLoaders with {num_neighbors} neighbors sampled per layer.\")\nprint(f\"Train loader will generate batches based on {train_data_split.edge_label_index.size(1)} prediction edges.\")\nprint(f\"Val loader will generate batches based on {val_loader.edge_label_index.size(1)} prediction edges.\")\nprint(f\"Test loader will generate batches based on {test_loader.edge_label_index.size(1)} prediction edges.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:54:10.008361Z","iopub.execute_input":"2025-05-11T11:54:10.008598Z","iopub.status.idle":"2025-05-11T11:54:12.895063Z","shell.execute_reply.started":"2025-05-11T11:54:10.008580Z","shell.execute_reply":"2025-05-11T11:54:12.894243Z"}},"outputs":[{"name":"stdout","text":"Created LinkNeighborLoaders with [10, 10] neighbors sampled per layer.\nTrain loader will generate batches based on 12889078 prediction edges.\nVal loader will generate batches based on 1611134 prediction edges.\nTest loader will generate batches based on 1611134 prediction edges.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"\n# Hyperparameters for the model and training\nin_channels = data_obj.num_node_features # Input dimension is the number of node features\nhidden_channels = 32 # Dimension of hidden layers\nout_channels = 1 # Output dimension for link prediction (a score)\nnum_layers = 2 # Number of graph convolution layers (matches num_neighbors length)\nlearning_rate = 0.01\nepochs = 5 # Reduced epochs for quicker testing with large data\n\nmodel_type = 'SAGE' # or 'SAGE'\n\n# Initialize the model on CPU first\nprint(f\"Initializing model ({model_type}) on CPU...\")\nmodel = LinkPredictor(in_channels, hidden_channels, out_channels, num_layers, model_type=model_type)\nprint(\"Model initialized on CPU.\")\n\n# Check for NaNs/Infs in model parameters (optional but good practice)\nfor name, param in model.named_parameters():\n    if torch.isnan(param).any() or torch.isinf(param).any():\n        print(f\"Warning: Parameter {name} contains NaN or Inf values after initialization.\")\n\n# Move the model to the selected device\nprint(f\"Moving model to {device}...\")\nmodel.to(device)\nprint(\"Model moved to device.\")\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nprint(\"Optimizer initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:54:12.896205Z","iopub.execute_input":"2025-05-11T11:54:12.896436Z","iopub.status.idle":"2025-05-11T11:54:13.044921Z","shell.execute_reply.started":"2025-05-11T11:54:12.896420Z","shell.execute_reply":"2025-05-11T11:54:13.044188Z"}},"outputs":[{"name":"stdout","text":"Initializing model (SAGE) on CPU...\nModel initialized on CPU.\nMoving model to cuda...\nModel moved to device.\nOptimizer initialized.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"num_neg_samples_for_ranking = 5 # Number of negative samples per positive edge for ranking","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:54:13.045881Z","iopub.execute_input":"2025-05-11T11:54:13.046495Z","iopub.status.idle":"2025-05-11T11:54:13.049918Z","shell.execute_reply.started":"2025-05-11T11:54:13.046465Z","shell.execute_reply":"2025-05-11T11:54:13.049281Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"for epoch in range(epochs):\n    # Train the model using the training loader\n    loss = train(model, train_loader, optimizer, device)\n\n    val_ranking_metrics = evaluate_ranking_metrics(model, val_data_split, device, num_neg_samples_for_ranking)\n\n    # Evaluate classification metrics\n    val_classification_metrics = evaluate_classification_metrics(model, val_loader, device)\n\n    # Print progress with multiple metrics\n    print(f'Epoch: {epoch+1:03d}, Loss: {loss:.4f}, '\n          f'Val AUC: {val_classification_metrics[\"roc_auc\"]:.4f}, Val F1: {val_classification_metrics[\"f1\"]:.4f}, Val MAP (flat): {val_classification_metrics[\"map\"]:.4f}, '\n          f'Val NDCG@{num_neg_samples_for_ranking}: {val_ranking_metrics[\"ndcg\"]:.4f}, Val MAP@{num_neg_samples_for_ranking}: {val_ranking_metrics[\"map_at_k\"]:.4f}')\n    if device.type == 'cuda':\n            torch.cuda.empty_cache()\n\nprint(\"\\nTraining finished.\")\n\n# Final evaluation on the test set after training\nfinal_test_classification_metrics = evaluate_classification_metrics(model, test_loader, device)\nfinal_test_ranking_metrics = evaluate_ranking_metrics(model, test_data_split, device, num_neg_samples_for_ranking)\n\nprint(f'Final Test AUC: {final_test_classification_metrics[\"roc_auc\"]:.4f}, '\n      f'Final Test F1: {final_test_classification_metrics[\"f1\"]:.4f}, '\n      f'Final Test MAP (flat): {final_test_classification_metrics[\"map\"]:.4f}, '\n      f'Final Test NDCG@{num_neg_samples_for_ranking}: {final_test_ranking_metrics[\"ndcg\"]:.4f}, '\n      f'Final Test MAP@{num_neg_samples_for_ranking}: {final_test_ranking_metrics[\"map_at_k\"]:.4f}')\ntorch.save(model.state_dict(), f'model_{model_type}_checkpoint_final.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:54:13.050762Z","iopub.execute_input":"2025-05-11T11:54:13.051000Z","iopub.status.idle":"2025-05-11T13:09:02.164453Z","shell.execute_reply.started":"2025-05-11T11:54:13.050982Z","shell.execute_reply":"2025-05-11T13:09:02.163590Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea256a4ef45149268674a78b6d850833"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e77f66bb0564d0f88ffff51e0619e36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b69e8fe80aaf43f3a11b461d229dccc3"}},"metadata":{}},{"name":"stdout","text":"Epoch: 001, Loss: 0.6306, Val AUC: 0.7894, Val F1: 0.7474, Val MAP (flat): 0.7629, Val NDCG@5: 0.7994, Val MAP@5: 0.3230\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ed0d36cacf541dcb71d0427e077e4a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2794d09d23ad4a31b5d6f1f6b9467937"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6b46108264d448da142087bf6d806b4"}},"metadata":{}},{"name":"stdout","text":"Epoch: 002, Loss: 0.5852, Val AUC: 0.7944, Val F1: 0.7617, Val MAP (flat): 0.7729, Val NDCG@5: 0.7804, Val MAP@5: 0.3127\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46d21010f94543acb119543742324ba5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8052469d0e2749598e39a1e6e10ed3af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"412308753b05491e919eba4fc6f9a90a"}},"metadata":{}},{"name":"stdout","text":"Epoch: 003, Loss: 0.5793, Val AUC: 0.7923, Val F1: 0.7643, Val MAP (flat): 0.7695, Val NDCG@5: 0.8172, Val MAP@5: 0.3085\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7439a697d3ec49199b952fac5e2d97f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b22610f7e64d4902921ef497a592e3ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1f06d574f2a4243a96bf2e0f1a84d42"}},"metadata":{}},{"name":"stdout","text":"Epoch: 004, Loss: 0.5773, Val AUC: 0.8019, Val F1: 0.7660, Val MAP (flat): 0.7807, Val NDCG@5: 0.7987, Val MAP@5: 0.3108\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85099b001283468aa0e603df34aefa40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb1b07df68740ceb47460fca7280860"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b1ec6d8ce28466c95dc9ba4e9c15c04"}},"metadata":{}},{"name":"stdout","text":"Epoch: 005, Loss: 0.5768, Val AUC: 0.7912, Val F1: 0.7635, Val MAP (flat): 0.7692, Val NDCG@5: 0.8126, Val MAP@5: 0.3007\n\nTraining finished.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"099bc71f6ac0410ba1b7724fc58bcec1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31fef88e7ab445aea0a14a38bff6f90f"}},"metadata":{}},{"name":"stdout","text":"Final Test AUC: 0.8039, Final Test F1: 0.7739, Final Test MAP (flat): 0.7823, Final Test NDCG@5: 0.8311, Final Test MAP@5: 0.3044\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"model.cpu()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T13:09:02.165549Z","iopub.execute_input":"2025-05-11T13:09:02.165898Z","iopub.status.idle":"2025-05-11T13:09:02.200792Z","shell.execute_reply.started":"2025-05-11T13:09:02.165871Z","shell.execute_reply":"2025-05-11T13:09:02.200073Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"model_type = 'GIN' # or 'SAGE'\n\n# Initialize the model on CPU first\nprint(f\"Initializing model ({model_type}) on CPU...\")\nmodel = LinkPredictor(in_channels, hidden_channels, out_channels, num_layers, model_type=model_type)\nprint(\"Model initialized on CPU.\")\n\n# Check for NaNs/Infs in model parameters (optional but good practice)\nfor name, param in model.named_parameters():\n    if torch.isnan(param).any() or torch.isinf(param).any():\n        print(f\"Warning: Parameter {name} contains NaN or Inf values after initialization.\")\n\n# Move the model to the selected device\nprint(f\"Moving model to {device}...\")\nmodel.to(device)\nprint(\"Model moved to device.\")\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nprint(\"Optimizer initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T13:09:02.201591Z","iopub.execute_input":"2025-05-11T13:09:02.201866Z","iopub.status.idle":"2025-05-11T13:09:02.315886Z","shell.execute_reply.started":"2025-05-11T13:09:02.201839Z","shell.execute_reply":"2025-05-11T13:09:02.315157Z"}},"outputs":[{"name":"stdout","text":"Initializing model (GIN) on CPU...\nModel initialized on CPU.\nMoving model to cuda...\nModel moved to device.\nOptimizer initialized.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"for epoch in range(epochs):\n    # Train the model using the training loader\n    loss = train(model, train_loader, optimizer, device)\n\n    # Evaluate classification metrics\n    val_classification_metrics = evaluate_classification_metrics(model, val_loader, device)\n\n    # Evaluate ranking metrics (NDCG, MAP@k)\n    # Note: This can be slow for large test sets as it iterates through positive edges.\n    # Adjust num_neg_samples_per_pos or sample a subset of positive edges for faster evaluation.\n    val_ranking_metrics = evaluate_ranking_metrics(model, val_data_split, device, num_neg_samples_for_ranking)\n\n\n    # Print progress with multiple metrics\n    print(f'Epoch: {epoch+1:03d}, Loss: {loss:.4f}, '\n          f'Val AUC: {val_classification_metrics[\"roc_auc\"]:.4f}, Val F1: {val_classification_metrics[\"f1\"]:.4f}, Val MAP (flat): {val_classification_metrics[\"map\"]:.4f}, '\n          f'Val NDCG@{num_neg_samples_for_ranking}: {val_ranking_metrics[\"ndcg\"]:.4f}, Val MAP@{num_neg_samples_for_ranking}: {val_ranking_metrics[\"map_at_k\"]:.4f}')\n\n\n    # Save model checkpoint (optional)\n    # torch.save(model.state_dict(), f'model_checkpoint_epoh_{epoch}.pth')\n\nprint(\"\\nTraining finished.\")\n\n# Final evaluation on the test set after training\nfinal_test_classification_metrics = evaluate_classification_metrics(model, test_loader, device)\nfinal_test_ranking_metrics = evaluate_ranking_metrics(model, test_data_split, device, num_neg_samples_for_ranking)\n\nprint(f'Final Test AUC: {final_test_classification_metrics[\"roc_auc\"]:.4f}, '\n      f'Final Test F1: {final_test_classification_metrics[\"f1\"]:.4f}, '\n      f'Final Test MAP (flat): {final_test_classification_metrics[\"map\"]:.4f}, '\n      f'Final Test NDCG@{num_neg_samples_for_ranking}: {final_test_ranking_metrics[\"ndcg\"]:.4f}, '\n      f'Final Test MAP@{num_neg_samples_for_ranking}: {final_test_ranking_metrics[\"map_at_k\"]:.4f}')\ntorch.save(model.state_dict(), f'model_{model_type}_checkpoint_final.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T13:09:02.316671Z","iopub.execute_input":"2025-05-11T13:09:02.316893Z","iopub.status.idle":"2025-05-11T14:23:21.618781Z","shell.execute_reply.started":"2025-05-11T13:09:02.316874Z","shell.execute_reply":"2025-05-11T14:23:21.617958Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a261ae2879245dbb8f57bf3322a3294"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a56c3a8bd3c441ad9ef068c56c027484"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ca9eff03f9041e6a8dc7f946f3ae69d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 001, Loss: 0.5558, Val AUC: 0.8508, Val F1: 0.7941, Val MAP (flat): 0.8434, Val NDCG@5: 0.7177, Val MAP@5: 0.3378\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f9f44bccba4403ab84955059ad06576"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53ac35543d9442f79629988432ff8b4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af1ad6a7f89a48b5aebffb44f8676883"}},"metadata":{}},{"name":"stdout","text":"Epoch: 002, Loss: 0.4867, Val AUC: 0.8660, Val F1: 0.8132, Val MAP (flat): 0.8596, Val NDCG@5: 0.6160, Val MAP@5: 0.3512\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85d8fdc989c841b585638bce3e2d6b15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8c01edfaf5a4aae9982854ce3a7ed7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"084fb7ffde9e432a8b1515193f2fedb5"}},"metadata":{}},{"name":"stdout","text":"Epoch: 003, Loss: 0.4730, Val AUC: 0.8679, Val F1: 0.8193, Val MAP (flat): 0.8609, Val NDCG@5: 0.6019, Val MAP@5: 0.3539\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e1ecaeba59c45ab928b02575e4c4aa5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f0cdb81ac9445a9d604da4335072c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74896e9e7b5a4b6c81d131e4c9087b25"}},"metadata":{}},{"name":"stdout","text":"Epoch: 004, Loss: 0.4676, Val AUC: 0.8742, Val F1: 0.8215, Val MAP (flat): 0.8680, Val NDCG@5: 0.7261, Val MAP@5: 0.3750\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/394 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb3550b9849b4a2f93fa13eb9dc67f6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2266384d656d47369188e6417540cb02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38be146446264133a32083a620832c48"}},"metadata":{}},{"name":"stdout","text":"Epoch: 005, Loss: 0.4645, Val AUC: 0.8722, Val F1: 0.8263, Val MAP (flat): 0.8663, Val NDCG@5: 0.7102, Val MAP@5: 0.3736\n\nTraining finished.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Classification Metrics:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1e50b9a551749fbbefec5846549b125"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Ranking Metrics:   0%|          | 0/787 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8dfc38a70b94c1c8da3b618533aadf5"}},"metadata":{}},{"name":"stdout","text":"Final Test AUC: 0.8878, Final Test F1: 0.8390, Final Test MAP (flat): 0.8817, Final Test NDCG@5: 0.7258, Final Test MAP@5: 0.3770\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"model.cpu()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T14:23:21.619822Z","iopub.execute_input":"2025-05-11T14:23:21.620640Z","iopub.status.idle":"2025-05-11T14:23:21.651368Z","shell.execute_reply.started":"2025-05-11T14:23:21.620599Z","shell.execute_reply":"2025-05-11T14:23:21.650769Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}